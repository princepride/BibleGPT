{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d56fc87018e48fd8c93d66b4139e3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Replacing layers...: 100%|██████████| 32/32 [00:04<00:00,  6.99it/s]\n",
      "Fusing layers...: 100%|██████████| 32/32 [00:00<00:00, 122.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Running model.generate:\n",
      "LLM output:  <s> <|system|>\n",
      "</s> \n",
      "<|user|>\n",
      "Tell me about AI</s> \n",
      "<|assistant|>\n",
      "Artificial intelligence (AI) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as learning, reasoning, and decision-making. These systems can process large amounts of data quickly and accurately, and they can adapt and improve their performance over time.\n",
      "\n",
      "AI is achieved through the use of machine learning algorithms, which enable computers to learn from data and make predictions or decisions based on that data. These algorithms are trained on vast datasets, which can include everything from medical records and weather data to social media posts and stock prices.\n",
      "\n",
      "Some examples of AI applications include:\n",
      "\n",
      "1. Speech and image recognition: AI systems can accurately identify spoken words and images, making them useful for applications like virtual assistants, smart home devices, and self-driving cars.\n",
      "\n",
      "2. Medical diagnosis: AI can help doctors to diagnose diseases more accurately by analyzing medical data and making predictions based on patterns in the data.\n",
      "\n",
      "3. Financial analysis: AI can help financial institutions to make more informed investment decisions by analyzing vast amounts of financial data.\n",
      "\n",
      "4. Robotics: AI can enable robots to navigate complex environments and interact with humans in a more intuitive and natural way.\n",
      "\n",
      "5. Personalized recommendations: AI can analyze user data to provide personalized recommendations for products, services, and content based on their preferences and behavior.\n",
      "\n",
      "The potential benefits of AI are numerous, but there are also concerns about its impact on society. Some experts have raised concerns about the potential for AI to replace human jobs, as well as issues related to privacy, security, and bias. As AI continues to develop, it will be important to ensure that it is used in a responsible and ethical manner.</s>\n"
     ]
    }
   ],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name_or_path = \"TheBloke/zephyr-7B-beta-AWQ\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=False)\n",
    "# Load model\n",
    "model = AutoAWQForCausalLM.from_quantized(model_name_or_path, fuse_layers=True,trust_remote_code=False, safetensors=True)\n",
    "\n",
    "prompt = \"Tell me about AI\"\n",
    "prompt_template=f'''<|system|>\n",
    "</s>\n",
    "<|user|>\n",
    "{prompt}</s>\n",
    "<|assistant|>\n",
    "'''\n",
    "\n",
    "print(\"*** Running model.generate:\")\n",
    "\n",
    "token_input = tokenizer(\n",
    "    prompt_template,\n",
    "    return_tensors='pt'\n",
    ").input_ids.cuda()\n",
    "\n",
    "# Generate output\n",
    "generation_output = model.generate(\n",
    "    token_input,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "# Get the tokens from the output, decode them, print them\n",
    "token_output = generation_output[0]\n",
    "text_output = tokenizer.decode(token_output)\n",
    "print(\"LLM output: \", text_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
